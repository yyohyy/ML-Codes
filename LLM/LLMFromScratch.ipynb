{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Working With Text Data"
      ],
      "metadata": {
        "id": "ge9RJ8xUgL0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        " \"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU0yaZISaTtR",
        "outputId": "5316f771-43b2-42c8-9004-3f99c4c06ac0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7f9f0339d650>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "print(\"Total number of characters:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wrqDHtWzo_h",
        "outputId": "0fcc3c4c-00a4-4cfb-bc05-5374f62921fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NUUhiJX58hzj"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGXl4Mfx0deB",
        "outputId": "e8462666-779f-473c-810e-f18c6c5b3d70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiFP6oER1FUb",
        "outputId": "1510205e-8af9-4374-fc20-332a9f3000cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted((set(preprocessed)))\n",
        "vocab_size= len(all_words)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cDsqFuJ1hiD",
        "outputId": "77634fc1-ead4-4522-b21a-0d7d9077a3ca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {token: integer for integer, token in enumerate(all_words)}\n",
        "for i, item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i >= 50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f871taD1SOr",
        "outputId": "1f43736b-0253-46c9-d884-62fca29e2236"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "    preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids): #D\n",
        "    text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "    text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) #E\n",
        "    return text"
      ],
      "metadata": {
        "id": "SEBwCfs68r6H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        " Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELBvEIwUyZR0",
        "outputId": "73e0f14a-913c-4043-d82a-7726c11142f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Version 2"
      ],
      "metadata": {
        "id": "M2V0cAIH-Nu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token: integer for integer, token in enumerate(all_tokens)}\n",
        "print(len(vocab.items()))"
      ],
      "metadata": {
        "id": "Ll8RbZ_lyztt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d2b67b-5568-4c49-d838-0d53b46f1e41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8Ar7HNQ-niI",
        "outputId": "b97ed0bb-d889-4f76-f56c-9e7379127833"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV2:\n",
        "  def __init__(self, vocab):\n",
        "    self.str_to_int = vocab\n",
        "    self.int_to_str = { i:s for s, i in vocab.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\#)', text)\n",
        "    preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
        "    ids = [self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self, ids):\n",
        "    text = \" \".join([self.int_to_str[i]for i in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "lcKBt8fy-wtn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Hello, artificial intelligence\"\n",
        "text2 = \"You are trending right now.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V3mQJLUBR5S",
        "outputId": "740a2def-36ad-4258-e713-baa425d1257f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, artificial intelligence <|endoftext|> You are trending right now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "print(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf0VzJq5Aoyh",
        "outputId": "c627cd56-ab78-4b54-a8d9-c157376188d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1131, 5, 1131, 7, 1131]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q79-AxiA1Rs",
        "outputId": "463f35ec-d732-480f-d381-8284fe2365eb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|unk|>, <|unk|>. <|unk|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byte Pair Encoding"
      ],
      "metadata": {
        "id": "t787xtMqF_NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS2hQ4nmA8Dx",
        "outputId": "c2d1b395-c64e-4dbd-cacd-1a52ae86630a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "\n",
        "print(\"Tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OeozTgwB_4P",
        "outputId": "d0e4fd7e-17cb-42f7-c13e-a67c5be6310a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiktoken version: 0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "knB4iq0OCLQV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        " \"of someunknownPlace.\"\n",
        ")\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmRxYHU4CUPI",
        "outputId": "14961178-8f1e-448e-8988-1e1e0b95ce5a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwFoGkmmClGp",
        "outputId": "b0ec0870-223e-4f19-dabd-e90cd1f0dc8c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Sampling with Sampling Window"
      ],
      "metadata": {
        "id": "_lCECKtCGBa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "id": "nsukZxKcEDBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0329514-d0b7-4a5c-bb04-992cd21e39b6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "A9DbUP6cGnvm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y: {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iH2t3U3Gqe4",
        "outputId": "59047af8-d92f-449c-df41-686c4d5ead2a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y: [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(context, \"--->\", desired)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m2GHMO-HC3H",
        "outputId": "d7df7314-a509-4c10-d319-61a7ea27e78f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ---> 4920\n",
            "[290, 4920] ---> 2241\n",
            "[290, 4920, 2241] ---> 287\n",
            "[290, 4920, 2241, 287] ---> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(tokenizer.decode(context), \"--->\", tokenizer.decode([desired]))"
      ],
      "metadata": {
        "id": "uJWraUwVHPoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b324bb-1e60-4c4d-af38-46861a4cfff2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and --->  established\n",
            " and established --->  himself\n",
            " and established himself --->  in\n",
            " and established himself in --->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "lsFGbiSN3_X0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i + 1:i + max_length + 1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "ucM8wQdi4lDX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4,\n",
        "                         max_length=256, stride=128,\n",
        "                         shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = shuffle,\n",
        "      drop_last = drop_last,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "-_wju42f5sKl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        " raw_text = f.read()\n",
        "\n",
        "dataloader = create_dataloader_v1(\n",
        "                  raw_text, batch_size = 1,\n",
        "                  max_length = 4, stride = 1,\n",
        "                  shuffle = False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxKmnH5N6gHe",
        "outputId": "8a783d13-6198-41f1-964d-1ceda94c4674"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "id": "dLo18PhSETOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41737b9a-64c5-4d80-ac1e-78954f47d3b3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=8, max_length=4, stride=4, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"\\nInput:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "id": "MwhMxlETdKeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb024915-143d-4f76-d099-765716e35923"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Token Embeddings"
      ],
      "metadata": {
        "id": "8t_WDhgOgmxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor([2,3,5,1])"
      ],
      "metadata": {
        "id": "-DBK3Sr_TMPE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3"
      ],
      "metadata": {
        "id": "zJKI86nZfZ6P"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFryvBiAffPp",
        "outputId": "4126e003-f8cd-42a4-bbac-42a40a690912"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW0ZBrxgf5lC",
        "outputId": "727b8ce8-8bcd-4d99-e48d-49bde0a61992"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSOt1xk_f6FE",
        "outputId": "a4b4e1ed-3f02-494b-a4f1-161d8037e971"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Word Positions"
      ],
      "metadata": {
        "id": "gz17HgBfg0ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50527\n",
        "output_dim = 256\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "F47980Wrg2z0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        " raw_text, batch_size=8, max_length=max_length,\n",
        " stride=max_length, shuffle=False\n",
        ")\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up5qx_vWhhzE",
        "outputId": "0dab25c6-f34a-4489-bc7c-5245f26e1e35"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNUBMdSz3_fq",
        "outputId": "8b4e5b2d-93bf-44ba-cf12-baa9606730c7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkIlJv135BxW",
        "outputId": "4c8ed97a-01b9-44a5-86e6-762607834e4a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Attention Mechanisms"
      ],
      "metadata": {
        "id": "FxvsU3n85EfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple self-attention mechanism without trainable weights"
      ],
      "metadata": {
        "id": "K0N_hmjV-4TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        " [[0.43, 0.15, 0.89], # Your (x^1)\n",
        " [0.55, 0.87, 0.66], # journey (x^2)\n",
        " [0.57, 0.85, 0.64], # starts (x^3)\n",
        " [0.22, 0.58, 0.33], # with (x^4)\n",
        " [0.77, 0.25, 0.10], # one (x^5)\n",
        " [0.05, 0.80, 0.55]] # step (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "bI6xMf4q5M-0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "attn_scores_2  = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] = torch.dot(x_i, query)\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMMMALZG4M_D",
        "outputId": "8e9ad20a-6670-4db0-c365-f22b1db439b3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "print(\"Attentions weights:\", attn_weights_2_tmp)\n",
        "print(\"Sum:\", attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-lnnaq35M6g",
        "outputId": "4d5db8cd-a05e-4d09-d8e2-43f025e66111"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attentions weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "Sum: tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "print(\"Attentions weights:\", attn_weights_2_naive)\n",
        "print(\"sum:\", attn_weights_2_naive.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO4DbSd15niL",
        "outputId": "922634a5-f37f-45de-c151-d4d7f6733a8f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attentions weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "print(\"Attention weights:\", attn_weights_2)\n",
        "print(\"Sum:\", attn_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbSeMqJl6KeD",
        "outputId": "87d3367c-0e91-4f83-a2fa-7c40fbe3e6d6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "Sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1]\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_2[i] * x_i\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io_ehn886gfn",
        "outputId": "07578e3f-d851-4397-e4ad-92f9ec3d3431"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computing attention weights for all input tokens"
      ],
      "metadata": {
        "id": "WdKysy2L_QOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = torch.empty(6, 6)\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSWJQzWg7KXp",
        "outputId": "d0f39e06-5da5-45dd-81e9-0ed2b42fa9aa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo1ZCO_r7_vJ",
        "outputId": "33ca1579-de28-4bfc-e9ac-e43f973632b3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKy6GIID8Mu5",
        "outputId": "ddbbdd89-0e23-497d-c47f-0c97d38c6d05"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
        "print(\"Row 2 sum:\", row_2_sum)\n",
        "print(\"All row sums:\", attn_weights.sum(dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRg5ptoZ8YES",
        "outputId": "113953ee-605d-48d8-81aa-3beefff09b9b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 2 sum: 1.0\n",
            "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOGG5Wy29ZSH",
        "outputId": "f2c7efeb-9fd9-4bdd-c174-8d3dacc5ba77"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Previous 2nd context vector:\", context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TME4svEP-dGk",
        "outputId": "4b3a6b59-8311-45d8-9612-24b33b3ad863"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous 2nd context vector: tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing self-attention with trainable weights"
      ],
      "metadata": {
        "id": "L51IngW4-x1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2"
      ],
      "metadata": {
        "id": "J4GzGG9YBhnf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d_in, d_out),requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.rand(d_in, d_out),requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.rand(d_in, d_out),requires_grad=False)"
      ],
      "metadata": {
        "id": "pX3qWF1r-2ad"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "print(query_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHqTZaCyBvNS",
        "outputId": "fe0e87c6-5f77-410a-ea4c-c7cce6d747ed"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4306, 1.4551])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "print('Key Shape:', keys.shape)\n",
        "print('Value Shape:', values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b7iw7BoCbjy",
        "outputId": "476f7fab-2ef9-48c4-8b88-fa3f10541a35"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Shape: torch.Size([6, 2])\n",
            "Value Shape: torch.Size([6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aMIAjS5CwGb",
        "outputId": "a7945be1-6ef9-44b8-86ef-34b368ab3f5c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.8524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW4F1ng6DDaH",
        "outputId": "cb40c3ba-13ed-427b-c3ec-cebca0ce03c3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k **0.5, dim=-1)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GraOxEStDJt2",
        "outputId": "fa136603-dc70-4497-c952-88895267b047"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA1xN9SvDqUC",
        "outputId": "63770d9b-3a5c-4abd-bb48-6b69e5fb3ab5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3061, 0.8210])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compact Self-Attention Python class"
      ],
      "metadata": {
        "id": "i3-Is-aqD2Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "J23LoeypDxdo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v1(nn.Module):\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @ self.W_query\n",
        "    values = x @ self.W_value\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "    )\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "ZxT20bjAD_Q6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOJeJVviXgCK",
        "outputId": "ad04c9fc-7874-4db8-c5cb-0c39e2047ea5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2996, 0.8053],\n",
            "        [0.3061, 0.8210],\n",
            "        [0.3058, 0.8203],\n",
            "        [0.2948, 0.7939],\n",
            "        [0.2927, 0.7891],\n",
            "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "  def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "    attn_scores = queries @ keys.T\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1] ** 0.5, dim=-1\n",
        "    )\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "3BeCxsJ6X9iv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3z_GMKOZcDQ",
        "outputId": "d467a55f-7cdb-43e0-de19-b65e28a758ba"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5337, -0.1051],\n",
            "        [-0.5323, -0.1080],\n",
            "        [-0.5323, -0.1079],\n",
            "        [-0.5297, -0.1076],\n",
            "        [-0.5311, -0.1066],\n",
            "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying a casual attention mask"
      ],
      "metadata": {
        "id": "CPJBD9QxaX9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRwobGzcZ6vs",
        "outputId": "b15c8aa9-527f-4019-c343-7bd500fc8c5d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
            "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
            "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
            "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
            "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E7FiFNnoluNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdcfC6Xrk0R3",
        "outputId": "a200e7d8-1640-4f61-d7d9-709dfb428202"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_simple = attn_weights * mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvxttUC9nOmN",
        "outputId": "cd867ec7-c533-4865-9340-1c4a599bbe17"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBiBQjWlnVZu",
        "outputId": "5acff43b-68cc-455a-fcb5-465d494bed6f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
            "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZEZsLa-navM",
        "outputId": "f95692b4-7a09-4af3-bf20-ec101936f9c5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3111,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.1655, 0.2602,   -inf,   -inf,   -inf,   -inf],\n",
            "        [0.1667, 0.2602, 0.2577,   -inf,   -inf,   -inf],\n",
            "        [0.0510, 0.1080, 0.1064, 0.0643,   -inf,   -inf],\n",
            "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121,   -inf],\n",
            "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MioXzSEniVx",
        "outputId": "79ac1b93-629d-4879-ae2f-23c42bde52b4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
            "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking additional attention weights with dropout"
      ],
      "metadata": {
        "id": "PMaRT9twnmbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "dropout = torch.nn.Dropout(0.5)\n",
        "example = torch.ones(6, 6)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SwliqUWykH1",
        "outputId": "f977771c-085c-4e26-eff7-18d4d248cf7a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2., 2., 2., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 2., 0., 0., 0., 2.],\n",
            "        [2., 0., 0., 0., 0., 2.],\n",
            "        [0., 2., 0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "print(dropout(attn_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd7o-7Kjzqrv",
        "outputId": "ca2c7dd1-2545-4fd5-dad2-80d29579f4ac"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 1.0335, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.6804, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4889, 0.5090, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3988, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.3418, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing a compact causal attention class"
      ],
      "metadata": {
        "id": "-lKVED680EmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "id": "YKhrkq6Mzxgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51388928-1c37-473f-b37b-0cd64ff85d85"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length,\n",
        "                        dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu(torch.ones(context_length, context_length),\n",
        "                   diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1,2)\n",
        "    attn_scores.masked_fill_(\n",
        "        self.mask.bool() [:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "    )\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "TlusmSOZ0Ffa"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
        "context_vecs = ca(batch)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG2cs-nX4Qou",
        "outputId": "d1cda080-466d-4de9-ea5f-e72b8ba5a785"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extending single-head attention to multi-head attention"
      ],
      "metadata": {
        "id": "JsmllybCSDK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stacking multiple single-head attention layers"
      ],
      "metadata": {
        "id": "ownniNkpSqsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length,\n",
        "               dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [CausalAttention(\n",
        "            d_in, d_out, context_length, dropout, qkv_bias\n",
        "        )\n",
        "        for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "L12qOxvRR3pC"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1]\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiHeadAttentionWrapper(\n",
        "    d_in, d_out, context_length, 0.0, num_heads=2\n",
        ")\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhlFCsg4UPS3",
        "outputId": "f3768a17-7435-4ed7-fad3-19a933046f64"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
            "\n",
            "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
            "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
            "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
            "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
            "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
            "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Implementing multi-head attention with weight splits"
      ],
      "metadata": {
        "id": "C6Fel8qBVPn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out,\n",
        "              context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    assert (d_out % num_heads == 0), \\\n",
        "      \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.register_buffer(\n",
        "        \"mask\",\n",
        "        torch.triu(torch.ones(context_length, context_length),\n",
        "                   diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_key(x)\n",
        "    values = self.W_value(x)\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(\n",
        "        b, num_tokens, self.num_heads, self.head_dim\n",
        "    )\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2,3)\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = (attn_weights @ values).transpose(1,2)\n",
        "\n",
        "    context_vec = context_vec.contiguous().view(\n",
        "        b, num_tokens, self.d_out\n",
        "    )\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec"
      ],
      "metadata": {
        "id": "mHtfIo5uVAyX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[[0.2745, 0.6584, 0.2775, 0.8573],\n",
        " [0.8993, 0.0390, 0.9268, 0.7388],\n",
        " [0.7179, 0.7058, 0.9156, 0.4340]],\n",
        " [[0.0772, 0.3565, 0.1479, 0.5331],\n",
        " [0.4066, 0.2318, 0.4545, 0.9737],\n",
        " [0.4606, 0.5159, 0.4220, 0.5786]]]])"
      ],
      "metadata": {
        "id": "9TwxULM6LqN0"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a @ a.transpose(2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5zkNUWxXGEo",
        "outputId": "079ef91f-3c6f-4274-bbce-4fea01b7fbc3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[1.3208, 1.1631, 1.2879],\n",
            "          [1.1631, 2.2150, 1.8424],\n",
            "          [1.2879, 1.8424, 2.0402]],\n",
            "\n",
            "         [[0.4391, 0.7003, 0.5903],\n",
            "          [0.7003, 1.3737, 1.0620],\n",
            "          [0.5903, 1.0620, 0.9912]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_head = a[0, 0, :, :]\n",
        "first_res = first_head @ first_head.T\n",
        "print(\"First head:\\n\", first_res)\n",
        "second_head = a[0, 1, :, :]\n",
        "second_res = second_head @ second_head.T\n",
        "print(\"\\nSecond head:\\n\", second_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvXgbMC5XGWM",
        "outputId": "24a13be4-ab3a-4d8f-aab9-ec8867338a79"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First head:\n",
            " tensor([[1.3208, 1.1631, 1.2879],\n",
            "        [1.1631, 2.2150, 1.8424],\n",
            "        [1.2879, 1.8424, 2.0402]])\n",
            "\n",
            "Second head:\n",
            " tensor([[0.4391, 0.7003, 0.5903],\n",
            "        [0.7003, 1.3737, 1.0620],\n",
            "        [0.5903, 1.0620, 0.9912]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "batch_size, context_length, d_in = batch.shape\n",
        "d_out = 2\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3emBVwWXQpK",
        "outputId": "712a437d-6231-4c81-a76b-a2a7f2b717bb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3190, 0.4858],\n",
            "         [0.2967, 0.3845],\n",
            "         [0.2875, 0.3551],\n",
            "         [0.2711, 0.3831],\n",
            "         [0.2652, 0.3897],\n",
            "         [0.2593, 0.3982]],\n",
            "\n",
            "        [[0.3190, 0.4858],\n",
            "         [0.2967, 0.3845],\n",
            "         [0.2875, 0.3551],\n",
            "         [0.2711, 0.3831],\n",
            "         [0.2652, 0.3897],\n",
            "         [0.2593, 0.3982]]], grad_fn=<ViewBackward0>)\n",
            "context_vecs.shape: torch.Size([2, 6, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a GPT model from scratch to generate text"
      ],
      "metadata": {
        "id": "M5kaSYo6aOb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coding an LLM architecture"
      ],
      "metadata": {
        "id": "eWVxl0cDbh60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "unmZOGyNbeJ1"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Placeholder GPT model architecture class"
      ],
      "metadata": {
        "id": "hhI-b9D0dCnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "    self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "    self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[DummyTransformerBlock(cfg)\n",
        "        for _ in range(cfg['n_layers'])]\n",
        "    )\n",
        "    self.final_norm = DummyLayerNorm(cfg['emb_dim'])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "        torch.arange(seq_len, device=in_idx.device)\n",
        "    )\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x= self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "      super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "      return x\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "  def __init__(self, normalized_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "-i_KsF3adGNH"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUHHWMCnfnsd",
        "outputId": "a9174f41-c560-4da9-badc-971b82f800f9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6109,  3626,  6100,   345],\n",
            "        [16833,  1110,  6622,   257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "logits = model(batch)\n",
        "print(\"output shape:\", logits.shape)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_OF-atqe9mG",
        "outputId": "452e0afa-041a-4260-9cb5-418bbbef974f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
            "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
            "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
            "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
            "\n",
            "        [[-1.5137,  1.0306, -0.7723,  ..., -1.8814, -0.6470,  0.2999],\n",
            "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
            "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
            "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalizing activations with layer normalization"
      ],
      "metadata": {
        "id": "7ff2TJ45gtNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "batch_example = torch.randn(2,5)\n",
        "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8xw0PsSgjh3",
        "outputId": "c4fe2214-4b1a-4ea9-abe5-1b79c91bd22d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
            "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "var = out.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrQu3psmhr0g",
        "outputId": "be6d51c3-6c41-4bad-ea10-c68b95cd05d9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[0.1324],\n",
            "        [0.2170]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[0.0231],\n",
            "        [0.0398]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_norm = (out-mean) / torch.sqrt(var)\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypllyZNLiR6R",
        "outputId": "fe060604-6714-4b8f-ef7d-d19c5d852c90"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized layer outputs:\n",
            " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
            "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
            "       grad_fn=<DivBackward0>)\n",
            "Mean:\n",
            " tensor([[9.9341e-09],\n",
            "        [1.9868e-08]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Var:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Feb-BctHjEjn",
        "outputId": "6f7f1e2c-3a2b-4f6e-c3a9-7c127dd1408f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    0.0000],\n",
            "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
            "Var:\n",
            " tensor([[1.0000],\n",
            "        [1.0000]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Layer Normalization Class"
      ],
      "metadata": {
        "id": "pNHqvcvLjWd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x = (x-mean) / torch.sqrt(var * self.eps)\n",
        "    return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "zGNl6wEdjQ6k"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = LayerNorm(emb_dim=5)\n",
        "out_ln = ln(batch_example)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t5508jfjwT-",
        "outputId": "fd67809f-efaf-42d8-b4a2-5139991c3ebc"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[    -0.0000],\n",
            "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[ 99999.9922],\n",
            "        [100000.0078]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0 /torch.pi)) *\n",
        "        (x+ 0.044716 * torch.pow(x,3))\n",
        "    ))"
      ],
      "metadata": {
        "id": "-foAdCFBlWf_"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "x = torch.linspace(-3, 2, 100)\n",
        "y_gelu, y_relu = gelu(x), relu(x)\n",
        "plt.figure(figsize=(8,3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], ['GELU', 'ReLU']), 1):\n",
        "  plt.subplot(1, 2, i)\n",
        "  plt.plot(x, y)\n",
        "  plt.title(f\"{label} activation function\")\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(f\"{label}(x)\")\n",
        "  plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "aaJtmTtHndRG",
        "outputId": "c8fc39d8-c419-4362-9dd2-941f43de2cef"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYVpJREFUeJzt3XlcVOX+B/DPzDDMsCuyySLiBiK4YZhWLl0Vt4pUrnVvV7S05Wo3oywxcy3JzK3UtFtqefOXuaRWauKWmfsOGigILuzKKsswy/n9QUwioAzbmeXzfr3mVXPmnDnf70Hm4TvPeZ5HIgiCACIiIiIiogaQih0AERERERGZPhYWRERERETUYCwsiIiIiIiowVhYEBERERFRg7GwICIiIiKiBmNhQUREREREDcbCgoiIiIiIGoyFBRERERERNRgLCyIiIiIiajAWFkQ1mDNnDiQSiSjnXr9+PSQSCVJTU5v93BqNBu+88w58fHwglUoRHh7e7DHUhZjXiIgs2/jx49G2bVtRzi1m23T37l1MnDgRHh4ekEgkmDp1qihxPIyY14hYWFiklJQUTJkyBZ06dYKtrS1sbW0RGBiIyZMn4+LFi1X2rfwFre2RmZkJAEhNTYVEIsEnn3xS63nbtm2LkSNH1vja6dOnIZFIsH79+kbL82FKSkowZ84cHDp0qNnOea8FCxZg+/btopy7NmvXrsWiRYswZswYfP3113jzzTdFjccYrxGROass2isfVlZW8PLywvjx45GWllav9zx06BAkEgm2bNlS6z4SiQRTpkyp8bUtW7ZAIpE062d1eno65syZg/PnzzfbOSuJ3TbVZsGCBVi/fj1ee+01bNiwAf/6179Ei8VYrxEBVmIHQM3rp59+wtixY2FlZYV//vOf6NatG6RSKRISErBt2zZ8/vnnSElJga+vb5XjPv/8c9jb21d7vxYtWjRT5I2vpKQEc+fOBQAMGDCgymszZ87E9OnTm/T8CxYswJgxY6r1CvzrX//Cc889B4VC0aTnr8mBAwfg5eWFpUuXNvu5a2KM14jIEsybNw9+fn4oKyvD8ePHsX79ehw5cgTx8fFQKpVih9fk0tPTMXfuXLRt2xbdu3ev8tp///tf6HS6Jju32G1TbQ4cOIBHH30Us2fPFuX89zLWa0QsLCxKcnIynnvuOfj6+mL//v1o3bp1ldcXLlyIVatWQSqt3pE1ZswYuLi4NFeoorOysoKVlTi/HjKZDDKZTJRzZ2dnm0SxKOY1IrIEw4YNQ69evQAAEydOhIuLCxYuXIidO3fi73//u8jRiUsul4t2bjHbpuzsbAQGBopybkOIeY2It0JZlI8//hjFxcVYt25dtaICqPhl/M9//gMfHx8Roqub3NxcvP322wgODoa9vT0cHR0xbNgwXLhwodq+ZWVlmDNnDjp16gSlUonWrVtj1KhRSE5ORmpqKlxdXQEAc+fO1Xf7z5kzB0D1ezSDgoIwcODAaufQ6XTw8vLCmDFj9Ns++eQT9O3bF61atYKNjQ1CQkKq3QIgkUhQXFyMr7/+Wn/u8ePHA6h9/MCqVavQpUsXKBQKeHp6YvLkycjPz6+yz4ABAxAUFITLly9j4MCBsLW1hZeXFz7++OMHXtfKW9kOHjyIS5cu6WM6dOiQ/jaG+7ucK4+59/a18ePHw97eHmlpaQgPD4e9vT1cXV3x9ttvQ6vVVrt2y5cvR3BwMJRKJVxdXTF06FCcPn3aKK8RkSV74oknAFR8QXWvhIQEjBkzBs7OzlAqlejVqxd27twpRoi4fv06/v3vf8Pf3x82NjZo1aoVIiIiahyLlZ+fjzfffBNt27aFQqGAt7c3xo0bh9u3b+PQoUN45JFHAAATJkzQf/5UftbdO8ZCrVbD2dkZEyZMqHaOwsJCKJVKvP322wCA8vJyzJo1CyEhIXBycoKdnR2eeOIJHDx4UH+MoW0TUDE2bv78+Wjfvj0UCgXatm2LGTNmQKVSVdmv8nbkI0eOIDQ0FEqlEu3atcM333zzwOta2QakpKTg559/1seUmppa62dxTe2GIZ+9jdl+N8c1or+wsLAgP/30Ezp06IDevXsbfGxubi5u375d5XH/H2zN4dq1a9i+fTtGjhyJJUuWYNq0aYiLi0P//v2Rnp6u30+r1WLkyJGYO3cuQkJCsHjxYrzxxhsoKChAfHw8XF1d8fnnnwMAnn32WWzYsAEbNmzAqFGjajzv2LFjcfjwYf2YkkpHjhxBeno6nnvuOf225cuXo0ePHpg3bx4WLFgAKysrRERE4Oeff9bvs2HDBigUCjzxxBP6c7/yyiu15j1nzhxMnjwZnp6eWLx4MUaPHo01a9ZgyJAhUKvVVfbNy8vD0KFD0a1bNyxevBgBAQF49913sXv37lrf39XVFRs2bEBAQAC8vb31MXXu3LnWY2qj1WoRFhaGVq1a4ZNPPkH//v2xePFifPHFF1X2e+mllzB16lT4+Phg4cKFmD59OpRKJY4fP26U14jIklX+4diyZUv9tkuXLuHRRx/FH3/8genTp2Px4sWws7NDeHg4fvjhh2aP8dSpUzh69Ciee+45fPrpp3j11Vexf/9+DBgwACUlJfr97t69iyeeeAKfffYZhgwZguXLl+PVV19FQkICbt26hc6dO2PevHkAgJdffln/+dOvX79q55TL5Xj22Wexfft2lJeXV3lt+/btUKlU+vahsLAQX375JQYMGICFCxdizpw5yMnJQVhYmH4sh6FtE1DRozRr1iz07NkTS5cuRf/+/RETE1OlXaqUlJSEMWPGYPDgwVi8eDFatmyJ8ePH49KlS7W+f+fOnbFhwwa4uLige/fu+pgq/7g3RF0+exu7/W6Oa0T3EMgiFBQUCACE8PDwaq/l5eUJOTk5+kdJSYn+tdmzZwsAanz4+/vr90tJSREACIsWLao1Bl9fX2HEiBE1vnbq1CkBgLBu3boH5lFWViZotdoq21JSUgSFQiHMmzdPv23t2rUCAGHJkiXV3kOn0wmCIAg5OTkCAGH27NnV9qnMu1JiYqIAQPjss8+q7Pfvf/9bsLe3r3LN7v1/QRCE8vJyISgoSHjyySerbLezsxMiIyOrnXvdunUCACElJUUQBEHIzs4WrK2thSFDhlTJfcWKFQIAYe3atfpt/fv3FwAI33zzjX6bSqUSPDw8hNGjR1c71/369+8vdOnSpcq2gwcPCgCEgwcPVtle+TO/92cWGRkpAKjysxAEQejRo4cQEhKif37gwAEBgPCf//ynWgyVPx9BMM5rRGTOKn+39u3bJ+Tk5Ag3b94UtmzZIri6ugoKhUK4efOmft+//e1vQnBwsFBWVqbfptPphL59+wodO3bUb6v8DNm8eXOt5wUgTJ48ucbXNm/eXONn0P3u/+wVBEE4duxYtd/3WbNmCQCEbdu2Vdu/8vPnQW1SZGSk4Ovrq3/+yy+/CACEH3/8scp+w4cPF9q1a6d/rtFoBJVKVWWfvLw8wd3dXXjxxRf12wxpm86fPy8AECZOnFhlv7ffflsAIBw4cEC/zdfXVwAgHD58WL8tOztbUCgUwltvvVXtXPerqQ2//7O4Uk3tRl0/exu7/W7Oa0SCwB4LC1FYWAgANQ7AHjBgAFxdXfWPlStXVttn69atiI2NrfJYt25dk8d9P4VCoR8DotVqcefOHdjb28Pf3x9nz56tEq+Liwtef/31au9Rn2noOnXqhO7du2PTpk36bVqtFlu2bMFTTz0FGxsb/fZ7/z8vLw8FBQV44oknqsRniH379qG8vBxTp06tMv5l0qRJcHR0rNITAlT8jF944QX9c2tra4SGhuLatWv1On99vPrqq1WeP/HEE1XOv3XrVkgkkhoHAdbn52OK14jImA0aNAiurq7w8fHBmDFjYGdnh507d8Lb2xtARS/2gQMH8Pe//x1FRUX6nuw7d+4gLCwMV69erfcsUvV172evWq3GnTt30KFDB7Ro0aJa+9CtWzc8++yz1d6jPp8/Tz75JFxcXKq0D3l5eYiNjcXYsWP122QyGaytrQFU3Aqam5sLjUaDXr161bt92LVrFwAgKiqqyva33noLAKp99gUGBupvawMqekj8/f2b7bOvLp+9jd1+m9o1MnUc3WIhHBwcAFR0Ad9vzZo1KCoqQlZWVpVf+Hv169evWQZvP+xDo/K+/FWrViElJaXKffutWrXS/39ycjL8/f0bdQDX2LFjMWPGDKSlpcHLywuHDh1CdnZ2lYYDqLjl7IMPPsD58+er3L9Z33m1r1+/DgDw9/evst3a2hrt2rXTv17J29u72rlatmxZbSrhplI5XuL+8+fl5emfJycnw9PTE87Ozo1yTlO7RkTGbuXKlejUqRMKCgqwdu1aHD58uMosbElJSRAEAe+//z7ef//9Gt8jOzsbXl5ejRbTwz5DS0tLERMTg3Xr1iEtLQ2CIOhfKygo0P9/cnIyRo8e3WhxWVlZYfTo0di4cSNUKhUUCgW2bdsGtVpdrX34+uuvsXjxYiQkJFS5RdPPz69e575+/TqkUik6dOhQZbuHhwdatGhR7bOvTZs21d7j/s/nplSXz97Gbr9N7RqZOhYWFsLJyQmtW7dGfHx8tdcqx1w09WJjSqUSpaWlNb5Wef/rw6YxXLBgAd5//328+OKLmD9/PpydnSGVSjF16tQmnf4PqCgsoqOjsXnzZkydOhXff/89nJycMHToUP0+v/32G55++mn069cPq1atQuvWrSGXy7Fu3Tps3LixSeOrVNtsSfc2soaorTG/fzD2w85vTBr7GhGZm9DQUP2sUOHh4Xj88cfxj3/8A4mJibC3t9d/3r799tsICwur8T3u/0PuQRQKRYPbh9dffx3r1q3D1KlT0adPHzg5OUEikeC5555r8vbhueeew5o1a7B7926Eh4fj+++/R0BAALp166bf53//+x/Gjx+P8PBwTJs2DW5ubpDJZIiJiak2KN5Qdf3iyljbh+b47BXrGlkaFhYWZMSIEfjyyy9x8uRJhIaGNvv5fX19cfny5RpfS0xM1O/zIFu2bMHAgQPx1VdfVdmen59fpUelffv2OHHiBNRqda1TAxrag+Dn54fQ0FBs2rQJU6ZMwbZt2xAeHl7lW7ytW7dCqVTil19+qbK9ptvG6nr+ymuSmJiIdu3a6beXl5cjJSUFgwYNMigPQ1UO1rx/sP793/IYon379vjll1+Qm5v7wF4LU7lGROas8o/fgQMHYsWKFZg+fbr+90wulzfK75evr6++HbifIe1DZGQkFi9erN9WVlZW7bOrffv2NX7Jdi9D24d+/fqhdevW2LRpEx5//HEcOHAA7733XrX42rVrh23btlV5//tvCTXk3L6+vtDpdLh69WqVyTaysrKQn5//0GvWUE3VPjRm+y32NbI0HGNhQd555x3Y2trixRdfRFZWVrXXm7oaHz58OG7dulVtJWWVSoUvv/wSbm5u6Nmz5wPfQyaTVYtz8+bN1e7lHT16NG7fvo0VK1ZUe4/K421tbQFU/0B8kLFjx+L48eNYu3Ytbt++Xa2bWyaTQSKRVPm2JjU1tcbVo+3s7Op07kGDBsHa2hqffvppldy/+uorFBQUYMSIEXWOvz58fX0hk8lw+PDhKttXrVpV7/ccPXo0BEHQL3B0r3tzNJVrRGTuBgwYgNDQUCxbtgxlZWVwc3PDgAEDsGbNGmRkZFTbPycnx6D3Hz58OI4fP44zZ85U2Z6fn49vv/0W3bt3h4eHxwPfo6b24bPPPqv27fno0aNx4cKFGmeuqjzezs5Of/66kEqlGDNmDH788Uds2LABGo2mxvbh3nMAwIkTJ3Ds2LEq+xnSNg0fPhwAsGzZsirblyxZAgBN/tnXvn17AKjSPmi12mqzABqisdtvsa+RpWGPhQXp2LEjNm7ciOeffx7+/v76lbcFQUBKSgo2btwIqVSqH5x3ry1bttQ48Hvw4MFwd3fXP9+/fz/Kysqq7RceHo6XX34Za9euRUREBF588UX06NEDd+7cwaZNmxAfH49vvvlGP7CtNiNHjsS8efMwYcIE9O3bF3Fxcfj222+rfEsNAOPGjcM333yDqKgonDx5Ek888QSKi4uxb98+/Pvf/8YzzzwDGxsbBAYGYtOmTejUqROcnZ0RFBSEoKCgWs//97//HW+//TbefvttODs7V/umbsSIEViyZAmGDh2Kf/zjH8jOzsbKlSvRoUOHavfvh4SEYN++fViyZAk8PT3h5+dX41TArq6uiI6Oxty5czF06FA8/fTTSExMxKpVq/DII4/UOi6msTg5OSEiIgKfffYZJBIJ2rdvj59++gnZ2dn1fs+BAwfiX//6Fz799FNcvXoVQ4cOhU6nw2+//YaBAwdiypQpAEznGhFZgmnTpiEiIgLr16/Hq6++ipUrV+Lxxx9HcHAwJk2ahHbt2iErKwvHjh3DrVu3qq0vtHXrViQkJFR738jISEyfPh2bN29Gv3798MorryAgIADp6elYv349MjIy6jRZyMiRI7FhwwY4OTkhMDAQx44dw759+6qMv6vMY8uWLfq2KCQkBLm5udi5cydWr16Nbt26oX379mjRogVWr14NBwcH2NnZoXfv3g8cCzF27Fh89tlnmD17NoKDg6tN1z1y5Ehs27YNzz77LEaMGIGUlBSsXr0agYGBVcY/GtI2devWDZGRkfjiiy+Qn5+P/v374+TJk/j6668RHh5e4/pLjalLly549NFHER0dre+B/u6776DRaOr9no3dfot9jSxOM89CRUYgKSlJeO2114QOHToISqVSsLGxEQICAoRXX31VOH/+fJV9HzTdLO6ZSq5y6tHaHhs2bBAEoWJqvTfffFPw8/MT5HK54OjoKAwcOFDYvXt3nWIvKysT3nrrLaF169aCjY2N8NhjjwnHjh0T+vfvL/Tv37/KviUlJcJ7772nP5eHh4cwZswYITk5Wb/P0aNHhZCQEMHa2rrK1HX3T1d3r8cee6zGqesqffXVV0LHjh0FhUIhBAQECOvWravx/RISEoR+/foJNjY2AgD9tKq1Td+3YsUKISAgQJDL5YK7u7vw2muvCXl5eVX2qWm6WEGoPj1ibWo7PicnRxg9erRga2srtGzZUnjllVeE+Pj4GqebtbOzq3Z8TflrNBph0aJFQkBAgGBtbS24uroKw4YNE86cOaPfxxivEZE5q/zdOnXqVLXXtFqt0L59e6F9+/aCRqMRBEEQkpOThXHjxgkeHh6CXC4XvLy8hJEjRwpbtmzRH1c59Whtj99++00QBEG4deuWMHHiRMHLy0uwsrISnJ2dhZEjRwrHjx+vU+x5eXnChAkTBBcXF8He3l4ICwsTEhISBF9f32rTVt+5c0eYMmWK4OXlJVhbWwve3t5CZGSkcPv2bf0+O3bsEAIDAwUrK6sqn3W1fVbodDrBx8dHACB88MEHNb6+YMECwdfXV1AoFEKPHj2En376qcb3M6RtUqvVwty5c/VtnY+PjxAdHV1lGmBBqH3K95raz5rUdnxycrIwaNAgQaFQCO7u7sKMGTOE2NjYGqebretnb2O33811jUgQJILA0ShERERERNQwHGNBREREREQNxsKCiIiIiIgajIUFERERERE1GAsLIiIiIiJqMBYWRERERETUYCwsiIiIiIiowSxugTydTof09HQ4ODgYtCQ8EZG5EgQBRUVFcHBwgKOjo0V/NrKNICKqqrKN8PT0hFT64D4Jiyss0tPT4ePjI3YYRERGqaCgAI6OjmKHIRq2EURENbt58ya8vb0fuI+ohUVMTAy2bduGhIQE2NjYoG/fvli4cCH8/f0feNzmzZvx/vvvIzU1FR07dsTChQsxfPjwOp3TwcEBQMXFMbTxVKvV2Lt3L4YMGQK5XG7QsabGknIFLCtf5mq+6ptvYWEhfHx8cPPmTf1npKViG1E3zNV8WVK+zLVuKtuIurQPohYWv/76KyZPnoxHHnkEGo0GM2bMwJAhQ3D58mXY2dnVeMzRo0fx/PPPIyYmBiNHjsTGjRsRHh6Os2fPIigo6KHnrOzadnR0rFejYWtrC0dHR4v4B2gpuQKWlS9zNV8NzdfSb4MC2EbUFXM1X5aUL3M1TF3aB1ELiz179lR5vn79eri5ueHMmTPo169fjccsX74cQ4cOxbRp0wAA8+fPR2xsLFasWIHVq1c3ecxERERERFSdUc0KVVBQAABwdnaudZ9jx45h0KBBVbaFhYXh2LFjTRobERERERHVzmgGb+t0OkydOhWPPfbYA29pyszMhLu7e5Vt7u7uyMzMrHF/lUoFlUqlf15YWAigoktIrVYbFGPl/oYeZ4osKVfAsvJlruarvvka4/URYwweERE1jNEUFpMnT0Z8fDyOHDnSqO8bExODuXPnVtu+d+9e2Nra1us9Y2NjGxqWybCkXAHLype5mi9D8y0pKWmiSOpPjDF4RETUMEZRWEyZMgU//fQTDh8+/NBprDw8PJCVlVVlW1ZWFjw8PGrcPzo6GlFRUfrnlSPbhwwZUq+BebGxsRg8eLBFDPKxlFwBy8qXuZqv+uZb2ZNrTDgGj4jI9IhaWAiCgNdffx0//PADDh06BD8/v4ce06dPH+zfvx9Tp07Vb4uNjUWfPn1q3F+hUEChUFTbLpfL6/2HRkOONTWWlCtgWfkyV/NSrtHhgz2X0UFteL6mcG3qOgbv3i+SgIoxeNu3b2/K0IiIjN7u+EwcyZRgqE5o0vOIWlhMnjwZGzduxI4dO+Dg4KAfJ+Hk5AQbGxsAwLhx4+Dl5YWYmBgAwBtvvIH+/ftj8eLFGDFiBL777jucPn0aX3zxhWh5EBGJ7YvDydh48hacFTI8/4wOJlAr1FlTjcEDOA6vvpir+bKkfC0l19zicsz+8Q/klcjQ9fRNPBfaxqDjDbk+ohYWn3/+OQBgwIABVbavW7cO48ePBwDcuHGjyvLhffv2xcaNGzFz5kzMmDEDHTt2xPbt23n/LBFZrNTbxfjsQBIAYISPDlYyo5rwr8GaagwewHF4DcVczZcl5Wvuuf4vSYq8Eila2wiwzY7Hrl3xBh1vyDg80W+FephDhw5V2xYREYGIiIgmiIiIyLQIgoD3d8RDpdGhb3tnhLhkix1So2rKMXgAx+HVF3M1X5aUryXkeiTpDk4dOwMJgOfaazEszPBcDRmHZxSDt4mIqH52XkjHb1dvw9pKinlPBeLSCfMoLJpjDB7AcXgNxVzNlyXla665lpRrMOvHywCAFx5tg7aSa/XK1ZD9zau/nIjIghSUqDH/p4pG4/WBHeDbqn637hijyZMn43//+x82btyoH4OXmZmJ0tJS/T7jxo1DdHS0/vkbb7yBPXv2YPHixUhISMCcOXNw+vRpTJkyRYwUiIhEtWzfVdzMLYWnkxJRgzo0yzlZWBARmaiFvyTg9t1ytHe1w8v924kdTqP6/PPPUVBQgAEDBqB169b6x6ZNm/T73LhxAxkZGfrnlWPwvvjiC3Tr1g1btmzhGDwiskhxtwrw5W/XAAAfPBsEe0Xz3KTEW6GIiEzQmet52HjiBgDgw2eDobCSQa3WiRxV4+EYPCKi+tFodZi+7SJ0AjCya2s8GeDebDNfsceCiMjEqLU6vPdDHABgTIg3Hm3XSuSIiIjIWHx1JAWX0gvhZCPH7Ke6NOu5WVgQEZmYdb+nICGzCC1t5ZgxvLPY4RARkZG4fqcYS2KvAADeG9EZrg7VJ6doSiwsiIhMyK28EiyNvQoAiB7eGc521iJHRERExkAQBLz3Q+X0460QEfLgKbqbAgsLIiITMmfnZZSqtQht64wxPZu/0SAiIuO09WwajiTdhsJKigXPBkMikTR7DCwsiIhMxN5Lmdj3RxaspBJ8+GwQpNLmbzSIiMj43L6rwgc/V0w/PnVQJ7R1sRMlDhYWREQmoFilwZydlwAAL/drh47uDiJHRERExmLej5eRX6JGYGtHTHzi4QuKNhUWFkREJuDT/VeRXlAG75Y2eP3JjmKHQ0RERuJgQjZ2XkiHVAIsHN0Vcpl4f96zsCAiMnIJmYX48kgKAGD+M0GwsZaJHBERERmDYpUGM7fHAwBeetwPwd5OosbDwoKIyIjpdBWzfGh1AoZ28cDAADexQyIiIiPxyd5EpOWXwrulDd4c3EnscFhYEBEZs81nbuLM9TzYWcsw++lAscMhIiIjce5GHtYfTQUALHg2GLbWVuIGBBYWRERGK7e4HDG7EwAAbw7uhNZONiJHRERExkCt1SF6WxwEARjVwwv9OrmKHRIAFhZEREbro91/IL9EjQAPB4zv21bscIiIyEh8cfgaEjKL4GxnjZkjjac3m4UFEZEROpWai+9P3wIAfPhsEKxEnOWDiIiMx7Wcu1i+/yoAYNbIQDjbWYsc0V/YUhERGRm1VoeZP1TM8jG2lw9CfJ1FjoiIiIyBTicgelscyjU69O/kime6e4odUhUsLIiIjMz631ORmFWElrZyTB8WIHY4RERkJDadvokTKbmwkcvwQXgQJBKJ2CFVwcKCiMiIpOeXYum+KwCA6GGd0dKIuriJiEg82YVlWLDrDwDA22H+8HG2FTmi6lhYEBEZkfk/XUZJuRa9fFtiTIi32OEQEZGRmL3zEorKNOjm7WS0E3qwsCAiMhIHE7OxOz4TMqkE88ODIJUaVxc3ERGJ45dLmdgdnwkrqQQxo7pCZqTtAwsLIiIjUKbWYvaOSwCACX3bonNrR5EjIiIiY1BYpsasHRUTerzcrx0CPY23fWBhQURkBD4/lIwbuSXwcFRi6uBOYodDRERG4uM9CcgqVMHPxQ7/+VtHscN5IBYWREQiS71djM9/TQYAvD8yEPYKK5EjIiIiY3AqNRf/O34DALDg2WAo5TKRI3owFhZERCISBAGzdl5CuUaHJzq6YHiwh9ghERGREVBptJi+9SIA4LlHfNCnfSuRI3o4FhZERCLaE5+Jw1dyYC2TYt4zxjcnORERiWPlwWQk5xTDxV6B6GGdxQ6nTlhYEBGJpFilwdwfLwMAXu3fDn4udiJHRERExuBKVhE+P5QEAJj7dBc42cpFjqhuWFgQEYnk0/1XkVlYBh9nG/x7YAexwyEiIiOg0wmYvvUi1FoBgzq7mdQtsiwsiIhEcCWrCF8dSQFQ8W2UsQ/IIyKi5vG/E9dx9kY+7BVWmB9uWrfIsrAgImpmgiBg5vZ4aHQCBge648kAd7FDIiIiI5CeX4qFuxMAAO8M9UdrJxuRIzIMCwsioma2/XwaTqbkQimXYvZTgWKHQ0RERkAQBLy/PR7F5Vr0bNMCL/T2FTskg7GwICJqRgWlanz4c8W3Ua8/2RHeLW1FjoiIiIzBz3EZ2J+QDblMgo9Gd4VUajq3QFUStbA4fPgwnnrqKXh6ekIikWD79u0P3P/QoUOQSCTVHpmZmc0TMBFRAy2NvYLbd1Vo52qHSU+0EzscIiIyAgUlaszZWTFL4GsDOqCTu4PIEdWPqIVFcXExunXrhpUrVxp0XGJiIjIyMvQPNze3JoqQiKjxXEovwDfHUgEA854OgrUVO42JiAhYsOsP3L6rQntXO0we2F7scOrNSsyTDxs2DMOGDTP4ODc3N7Ro0aLxAyIiaiI6XcW9szoBGNG1NR7v6CJ2SEREZASOJt/GptM3AQAfje4KhZXpzhIoamFRX927d4dKpUJQUBDmzJmDxx57rNZ9VSoVVCqV/nlhYSEAQK1WQ61WG3Teyv0NPc4UWVKugGXly1zFseVsGs7eyIedtQzTwzo2SUz1zdcYrg8RkSUqU2sxY1scAOCfvdvgkbbOIkfUMCZVWLRu3RqrV69Gr169oFKp8OWXX2LAgAE4ceIEevbsWeMxMTExmDt3brXte/fuha1t/QZNxsbG1us4U2RJuQKWlS9zbT4lGuCDczIAEgxqXY6zRw406fkMzbekpKSJIiEiogdZvv8qUu+UwN1RgXeHBYgdToOZVGHh7+8Pf39//fO+ffsiOTkZS5cuxYYNG2o8Jjo6GlFRUfrnhYWF8PHxwZAhQ+Do6GjQ+dVqNWJjYzF48GDI5aaxtHp9WVKugGXly1yb3+wfL6NYcwsd3ewQM6EP5LKmGVtR33wre3KJiKj5XE4vxBeHrwEA5j0TBEel6bfJJlVY1CQ0NBRHjhyp9XWFQgGFQlFtu1wur/cfGg051tRYUq6AZeXLXJtH3K0C/N+pWwCA+eHBsFVW/zxqbIbmayn/DoiIjIVWJ2D6tovQ6gQMC/JAWBcPsUNqFCY/Jcn58+fRunVrscMgIqpGpxMwc0c8BAEI7+6JR9u1Ejskk8IpyYnIXK37PQUXbxXAQWmFuU93ETucRiNqj8Xdu3eRlJSkf56SkoLz58/D2dkZbdq0QXR0NNLS0vDNN98AAJYtWwY/Pz906dIFZWVl+PLLL3HgwAHs3btXrBSIiGq16fRNXLiZDweFFWaM6Cx2OCanckryF198EaNGjarzcYmJiVVudeWU5ERkTG7mlmDx3isAgBnDO8PNUSlyRI1H1MLi9OnTGDhwoP555ViIyMhIrF+/HhkZGbhx44b+9fLycrz11ltIS0uDra0tunbtin379lV5DyIiY5BXXI6FeypW2J46uBPcHMyn4WgunJKciMyNIAh4b3s8StVahPo5Y2wvH7FDalSiFhYDBgyAIAi1vr5+/foqz9955x288847TRwVEVHDffxLIvJL1AjwcEBkH1+xw7EonJK86TFX82VJ+YqR644LGTh8JQfWVlLMf6oztFoNtNqmP29DcjXkGJMfvE1EZGzO38zHd6cqelvnPRMEqyaaBYqq4pTkzY+5mi9Lyre5cr2rBhacr5h6fHBrNRJO/YqEZjnzX+qTqyFTkrOwICJqRFqdgFl/Dtge1dMLoX6mvdiRKeGU5M2HuZovS8q3uXOdtiUOxZoMdHKzx8cvPgprq+b70qkhuRoyJTkLCyKiRvTdqRsVM30orBA9jAO2xcYpyZsWczVflpRvc+R6+EoOtl/IgEQCLBzTFXY2TT/1eE3qk6sh+7N/noiokeQWl+PjPYkAgKghneDqIE7DQX/hlOREJLaScg1m/BAHAIjs0xY92rQUOaKmwx4LIqJGsuiXBBSUqtG5tSP+9SgHbDcUpyQnInOwNPYKbuWVwquFDd4O83/4ASaMhQURUSM4dyMP3526CQCY/0wXDthuBJySnIhM3cVb+fjqSAoA4IPwINgrzPtPb/POjoioGVQM2L4EQQBG9/RGr7YcsN0YOCU5EZkytVaH6VvjoBOAp7p5YmCA+S/Wya/UiIga6P9O3kBcWgEclFaYPixA7HCIiMgIfHUkBZczCtHCVo7ZTwWKHU6zYGFBRNQAd+6qsOiXigHbbw3mgG0iIgJSbxdjaewVAMDMEYFwsbeMtoGFBRFRA3y8JxEFpWoEtnbECxywTURk8QRBwIwf4qDS6PB4BxeM7ukldkjNhoUFEVE9nb2Rh02n/xywHc4B20REBGw+cwtHk+9AKZfiw2eDIJFIxA6p2bAVJCKqh8oVtgFgTIg3Qnw5YJuIyNLlFKnw4c9/AADeHNQJvq3sRI6oebGwICKqh40nbyA+rZADtomISG/eT5dRUKpGF09HvPS4n9jhNDsWFkREBrpzV4VFexIAAG8P8beYQXlERFS7AwlZ+PFCOmRSCRaO7mqRt8daXsZERA20cE8CCss06OLJAdtERATcVWkw84eK22NfetwPQV5OIkckDhYWREQGOHM9D9+fvgUAmPdMEGRSyxmUR0RENfvkl0SkF5TBx9kGUwd1FDsc0bCwICKqI61OwPvbK76R+nsvb4T4thQ5IiIiEtvZG3n4+lgqAGDBs8GwtbYSNyARsbAgIqqjb09cx+WMQjgqrfDuUA7YJiKydOUaHaZvvQhBAEb39MYTHV3FDklULCyIiOrg9j0rbE8L80crDtgmIrJ4a35NxpWsu2hlZ42ZIzqLHY7oWFgQEdXBR7sTUFSmQZCXI/7RmwO2iYgsXVL2XXx2IAkAMOupQLS0sxY5IvGxsCAieojTqbnYcqZiwPZ8DtgmIrJ4Op2AGdviUK7VYYC/K57u5il2SEahXqNLUlJS8Ntvv+H69esoKSmBq6srevTogT59+kCpVDZ2jEREotFodXh/xyUAwHOP+KBHGw7YJiKydP936gZOpubC1lqGD8KDIJHwCyfAwMLi22+/xfLly3H69Gm4u7vD09MTNjY2yM3NRXJyMpRKJf75z3/i3Xffha8vbxUgItO34fh1/JFRCCcbOd7hgG0iIouXVViGj3b9tUiqd0tbkSMyHnUuLHr06AFra2uMHz8eW7duhY+PT5XXVSoVjh07hu+++w69evXCqlWrEBER0egBExE1l+yiMizZewVAxYBtZ94/Wyfs1SYiczZrRzyKVBp082mByL5txQ7HqNS5sPjoo48QFhZW6+sKhQIDBgzAgAED8OGHHyI1NbUx4iMiEs1HuxJQpNKgq7cTng9tI3Y4Ro+92kRk7vbEZ+CXS1mwkkrw0ahgjrm7T50LiwcVFfdr1aoVWrVqVa+AiIiMwYlrd7DtXBokEg7Yrgv2ahORuSsoVWPWn2PuXunfDp1bO4ockfGp16xQ69evr3G7RqNBdHR0Q+IhIhKdWqvTNx7Ph7ZBN58W4gZkAj766COcOHEC//73v6sVFcBfvdqrV69GQkIC2rVrJ0KURET1t3BPArKLVPBzscPrT3YUOxyjVK/C4j//+Q8iIiKQl5en35aYmIjevXvj//7v/xotOCIiMXx9NBWJWUVoaSvHtCH+YodjEgzt1Q4JCWnCaIiIGteJa3ew8cQNAEDMqGAo5TKRIzJO9Soszp07h1u3biE4OBixsbFYuXIlevbsiYCAAFy4cKGxYyQiajaZBWVYGlsxYHv6sAAueFQP7NUmInNSptYi+oc4ABXTjj/ajrf716ZehUX79u3x+++/Y9SoURg6dCjefPNNfPnll/j222/h5OTU2DESETWbD36+jOJyLXq2aYGIkOq39NDDsVebiMzJyoNJuJZTDFcHBaKHdRY7HKNW75W3f/75Z3z33Xfo06cPWrRoga+++grp6emNGRsRUbM6cvU2frqYAakEmB8eBCkHbNcLe7WJyFwkZBbi80PJAIC5T3eBk61c5IiMW70Ki1deeQURERF499138dtvv+HixYuwtrZGcHAwvv/++8aOkYioyak0WszaEQ8AGNenLbp4sve1vtirTUTmQKsTMH1rHDQ6AYMD3TEsyEPskIxevQqL33//HSdOnMBbb70FiUQCDw8P7Nq1C/PmzcOLL77Y2DESETW5L39LwbXbxXCxVyBqSCexwzF57NUmIlO34Vgqzt/Mh73CCvOfCYJEwl7sh6lXYXHmzBl069at2vbJkyfjzJkzdX6fw4cP46mnnoKnpyckEgm2b9/+0GMOHTqEnj17QqFQoEOHDrUOEiQiqqubuSX4dP9VAMB7IwLgqGRXd0OwV5uITF1afik+/iURAPDuUH94OClFjsg01KuwUCgUtb7m71/3qRmLi4vRrVs3rFy5sk77p6SkYMSIERg4cCDOnz+PqVOnYuLEifjll1/qfE4iovvN/fESVBodHm3njPDuXmKHY/LYq01EpkwQBMz8IQ4l5Vr08m2Jf/b2FTskk1HnlbeHDh2KOXPm4NFHH33gfkVFRVi1ahXs7e0xefLkB+47bNgwDBs2rK4hYPXq1fDz88PixYsBAJ07d8aRI0ewdOlSg+ZQJyKqFHs5C/v+yIaVVIIPwtnV3RjOnDlT4xdQkydPxqBBg0SIiIio7n68mIGDiTmwlkkRMyqYE3kYoM6FRUREBEaPHg0nJyc89dRT6NWrFzw9PaFUKpGXl4fLly/jyJEj2LVrF0aMGIFFixY1erDHjh2r1iiFhYVh6tSptR6jUqmgUqn0zwsLCwEAarUaarXaoPNX7m/ocabIknIFLCtf5vqX0nIt5uysGLD90mNt4dtSadLXpb4/28bOubF6tYmImltecTnm7rwEAPj3wPbo6O4gckSmpc6FxUsvvYQXXngBmzdvxqZNm/DFF1+goKAAACCRSBAYGIiwsDCcOnUKnTs3zRy/mZmZcHd3r7LN3d0dhYWFKC0thY2NTbVjYmJiMHfu3Grb9+7dC1tb23rFERsbW6/jTJEl5QpYVr7MFfjxuhRp+VK0sBbQXnUVu3ZdbebImoahP9uSkpIGn7MperWJiJrbh7v+wJ3icnR0s8drA9qLHY7JqXNhAVR8C/XCCy/ghRdeAAAUFBSgtLQUrVq1glxunIMdo6OjERUVpX9eWFgIHx8fDBkyBI6Ojga9l1qtRmxsLAYPHmy0+TYWS8oVsKx8mWuFq9l3cejEMQACFozugcGBbuIE2Yjq+7Ot7MltCGPo1SYiaojfk25jy5lbkEiAj0YHQ2ElEzskk2NQYXE/JyenZp2T3MPDA1lZWVW2ZWVlwdHRscbeCqCiGKqpW14ul9f7j6qGHGtqLClXwLLyteRcBUHA3J8SoNEJ+FuAG4Z19TSrsRWG/mwb49+BMfRqExHVV5laixk/xAEA/vWoL0J8nUWOyDQZVFh8+umnNW53cnJCp06d0KdPn0YJqjZ9+vTBrl27qmyLjY1t8vMSkXn54VwaTqTkQimXYs7TXcyqqBCTKfZqExEBwLJ9V3H9Tgk8HJWYFsaxYPVlUGGxdOnSGrfn5+ejoKAAffv2xc6dO+HsXLcq7+7du0hKStI/T0lJwfnz5+Hs7Iw2bdogOjoaaWlp+OabbwAAr776KlasWIF33nkHL774Ig4cOIDvv/8eP//8syFpEJEFKyhR48Of/wAA/OdvHeHjXL+xVvRwzd2rTURUH5czCvHf364BAOaHB8GBaxnVm0GFRUpKSq2vXbt2DS+88AJmzpyJVatW1en9Tp8+jYEDB+qfV46FiIyMxPr165GRkYEbN27oX/fz88PPP/+MN998E8uXL4e3tze+/PJLTjVLRHW28JcE3CkuRwc3e0x8vJ3Y4ZiVxu7VPnz4MBYtWoQzZ84gIyMDP/zwA8LDwx94zKFDhxAVFYVLly7Bx8cHM2fOxPjx4w06LxFZDq0AzNxxGVqdgBHBrTE40P3hB1GtGjTG4l7t2rXDRx99ZNDiRwMGDIAgCLW+XtOq2gMGDMC5c+fqEyIRWbgz1/Ow8UTFlxUfhgfB2qpea4RSLRq7V7tyEdUXX3wRo0aNeuj+lYuovvrqq/j222+xf/9+TJw4Ea1bt+YXUERUo8MZEsSlFcJRaYXZTwWKHY7Ja7TCAgDatGmDzMzMxnxLIqJGodHq8N6fA/PGhHijd7tWIkdkfhq7V5uLqBJRU7qZV4JdNyu+YHpvRGe4OSpFjsj0NerXdXFxcfD15bLnRGR81h9NRUJmEVrYyhE9LEDscCxOZa/23r17m+wctS2ieuzYsSY7JxGZJkEQMGvnHyjXSdDbryX+3stH7JDMgkE9FrXNdV5QUIAzZ87grbfeQmRkZKMERkTUWDIKyrAk9goAIHpYAFrZ174yNDWdpu7Vrs8iqiqVCiqVSv+8sp1Tq9X1XsHclFdvryvmar4sJd8d59NxJOkOrCQCZg/vBI1GI3ZITaohP1dDjjGosGjRokWt0zJKJBJMnDgR06dPN+QtiYia3Lyf/kBJuRa9fFsiIoTfSonFGHu1Y2JiMHfu3Grb9+7dC1vb+s0YxlXtzZMl5QqYd7531cCC8zIAEgz10eHq2d9xVeygmkl9fq4lJSV13tegwuLgwYM1bnd0dETHjh2hVCqRnZ0NT09PQ96WiKjJXMyVYF9iDqykEiwYFQyplGtWNBWxe7Xrs4hqdHS0fkZCoCIHHx8fDBkyBI6Ojgadn6vamydLyhWwjHzf3hKHYk0G/N3t8GTrArPOtVJDfq61fbbXxKDCon///g98/cKFC+jZsye0Wq0hb0tE1CTuqjTYklIxlOyV/u3Qyd1B5IjMm9i92vVZRFWhUEChqH5rXENWprfkVe3NmSXlCphvvr9eycGOCxmQSoAF4UG4dfF3s821JvXJ1ZD9G3VWKCIiY7J8fxIKyiXwaWmD15/sKHY4Zq+xe7W5iCoRNaZilQYztlXMDjjhMT909XbCrYsiB2VmWFgQkVmKu1WAb45XrFkx9+nOUMplIkdk/hq7V5uLqBJRY1oSewVp+aXwamGDqMGdANS+lhrVDwsLIjI7Gq0O07ddhE4AerbS4YkOLmKHRPXARVSJqLFcuJmPdb9XrLXz4bNBsFNYmf3MV2IwqLC4ePHB/UWJiYkNCoaIqDGs+z0Vl9IL4WRjhWfblokdDhERiUit1eHdrRVfNoV398QAfzexQzJbBhUW3bt3h0QiqfEbpMrttQ3cIyJqDjdzS/RrVrwb5g+7rAsiR0RERGL672/XkJBZhJa2crw/MlDscMyaQYVFSkpKU8VBRNRggiBg5vZ4lKq16O3njDE9PbF7NwuL5sJebSIyNim3i7FsX8UqFe+PDOQCqU3MoMLC2BY2IiK6184L6fj1Sg6sZVIsGBXMHtRmxl5tIjImgiAgettFlGt0eKKjC57t4SV2SGbPoMLi448/xuuvv65faOj3339Hr1699HOAFxUV4d1338WqVasaP1IiogfIKy7HvB8vAwAmD+yA9q72HJjXzNirTUTG5PvTN3H8Wi5s5DJ8GM4vm5qDQYVFdHQ0xo8fry8shg0bhvPnz6Ndu3YAKpb8XrNmDQsLImp2H/z8B+4Ul6OTuz1eG9Be7HAsEnu1ichYZBeV4cOf/wAARA3uhDatbEWOyDJIDdn5/u7tB00DSETUXH67moOtZ29BIgE+Gt0V1lYGfbRRE/jtt9/wwgsvoE+fPkhLSwMAbNiwAUeOHBE5MiKyBHN3XkZhmQbBXk6Y8FhbscOxGGx9iciklZRrMOOHipVUI/u0Rc82LUWOiLZu3YqwsDDY2Njg3LlzUKlUAICCggIsWLBA5OiIyNztu5yFn+MyIJNKEDMqGFYy/rnbXHilicikLd57BTdzS+HppMTbYf5ih0MAPvjgA6xevRr//e9/IZfL9dsfe+wxnD17VsTIiMjcFZWpMXN7PABg4hN+CPJyEjkiy2Lwyttffvkl7O3tAQAajQbr16+Hi0vFqrZFRUWNGx0R0QOcvZGHtZUrqY4Khr3C4I80agKJiYno169fte1OTk7Iz89v/oCIyGIs+iURmYVlaONsi6l/6yR2OBbHoFa4TZs2+O9//6t/7uHhgQ0bNlTbh4ioqak0Wry75SIEARjVwwsDuZKq0fDw8EBSUhLatm1bZfuRI0f0k30QETW2M9dzseH4dQBAzKhg2FjLRI7I8hhUWKSmpjZRGEREhll5IAlXs+/Cxd6aK6kamUmTJuGNN97A2rVrIZFIkJ6ejmPHjuGtt97CrFmzxA6PiMyQSqPF9K1xEARgTIg3HuvgInZIFsmgwqKsrAz79u3DyJEjAVRMP1s5KA8ArKysMG/ePCiVysaNkojoHn9kFGLVoWQAwNyng9DSzlrkiOhe06dPh06nw9/+9jeUlJSgX79+UCgUmDZtGiZOnCh2eERkhlYfuoar2XfRys4a7w3vLHY4Fsugwdvr16/HmjVr9M9XrFiBo0eP4ty5czh37hw2bNjANSyIqEmptTq8vfkCNDoBQwLdMTzYQ+yQ6D4SiQTvvfcecnNzER8fj+PHjyMnJwdOTk7w8/MTOzwiMjNJ2UVYeTAJADDrqUB+2SQigwqLb7/9Fi+//HKVbRs3bsTBgwdx8OBBLFq0CJs3b27UAImI7rXm12RcSi+Ek40cHzwbxJVUjYhKpUJ0dDR69eqFxx57DLt27UJgYCAuXboEf39/LF++HG+++abYYRKRGdHpBEzfGodyrQ4D/V3xdDdPsUOyaAbdCpWUlITg4GD9c6VSCan0r9okNDQUkydPbrzoiIjukZhZhOX7rwIA5jwdCDcH3nZpTGbNmoU1a9Zg0KBBOHr0KCIiIjBhwgQcP34cixcvRkREBGQyDqYkosaz8eQNnL6eB1trGT54NphfNonMoMIiPz+/ypiKnJycKq/rdLoqrxMRNRaNVodpWy5ArRXwtwA3hHf3Ejskus/mzZvxzTff4Omnn0Z8fDy6du0KjUaDCxcusLEnokaXWVCGj3YnAACmhfnDq4WNyBGRQbdCeXt7Iz4+vtbXL168CG9v7wYHRUR0vzWHr+HirQI4Kq2wYBS/lTJGt27dQkhICAAgKCgICoUCb775Jn9WRNToBEHArB3xuKvSoLtPC4zr01bskAgGFhbDhw/HrFmzUFZWVu210tJSzJ07FyNGjGi04IiIACAhsxDL9l0BAMx6qgvcHXkLlDHSarWwtv5r0KSVlZV+QVUiosa0Jz4Tey9nwUoqwUejgyGT8gsMY2DQrVAzZszA999/D39/f0yZMgWdOlWsaJiYmIgVK1ZAo9FgxowZTRIoEVkmtVaHt76vuAVqUGd3jO7JW6CMlSAIGD9+PBQKBYCKKcpfffVV2NnZVdlv27ZtYoRHRGaioFSNWTsvAQBeG9AeAR6OIkdElQwqLNzd3XH06FG89tprmD59OgRBAFAxteDgwYOxatUquLu7N0mgRGSZVhxIwqX0QrSwlWPBKM4CZcwiIyOrPH/hhRdEioSIzNlHu/9ATpEK7VztMHlgB7HDoXsYVFgAgJ+fH/bs2YPc3FwkJVXMGdyhQwc4Ozs3enBEZNni0wr0c5PPfyaIs0AZuXXr1okdAhGZuePX7uD/Tt4EAMQ8GwylnDPNGRODC4tKzs7OCA0NbcxYiIj0ytRaTN10HhqdgBHBrfEU5yYnIrJoZWotZmyLAwA8H9oGvdu1Ejkiup9Bg7ebysqVK9G2bVsolUr07t0bJ0+erHXf9evXQyKRVHkolfwWk8jcfLwnEUnZd+HqoMAH4UFih0NERCJbcSAJ124Xw81BgenDAsQOh2ogemGxadMmREVFYfbs2Th79iy6deuGsLAwZGdn13qMo6MjMjIy9I/r1683Y8RE1NSOJt3G2t9TAAAfj+mKlnbWDzmCiIjMWUJmIVb/mgwAmPdMFzjZyEWOiGoiemGxZMkSTJo0CRMmTEBgYCBWr14NW1tbrF27ttZjJBIJPDw89A8OGCcyHwWlary9+QIA4B+922Cgv5vIERERkZi0OgHvbo2DRicgrIs7hga1FjskqoWohUV5eTnOnDmDQYMG6bdJpVIMGjQIx44dq/W4u3fvwtfXFz4+PnjmmWdw6dKl5giXiJrBrB3xSC8og28rW7w3vLPY4RARkci+OZaKCzfz4aCwwrxneGusMav34O3GcPv2bWi12mo9Du7u7khISKjxGH9/f6xduxZdu3ZFQUEBPvnkE/Tt2xeXLl2qcdVvlUoFlUqlf15YWAgAUKvVUKvVBsVbub+hx5kiS8oVsKx8jTnXnRcysON8OmRSCRaNDoK1VGhQnMaca1Oob76Wcn2IyPSk5Zdi0S+JAIB3hwVwgVQjJ2phUR99+vRBnz599M/79u2Lzp07Y82aNZg/f361/WNiYjB37txq2/fu3QtbW9t6xRAbG1uv40yRJeUKWFa+xpbrnTLg44syABIM9tQgI+4oMuIa572NLdemZmi+JSUlTRQJEVH9CYKAmT/EoaRci9C2zvhHaBuxQ6KHELWwcHFxgUwmQ1ZWVpXtWVlZ8PDwqNN7yOVy9OjRQ7+mxv2io6MRFRWlf15YWAgfHx8MGTIEjo6GrdSoVqsRGxuLwYMHQy4370FDlpQrYFn5GmOuWp2AF9aeQpk2Hz18nLD0pUdgJWv4nZrGmGtTqm++lT25RETG5MeLGTiYmANrmRQLRgVDKuUCqcZO1MLC2toaISEh2L9/P8LDwwEAOp0O+/fvx5QpU+r0HlqtFnFxcRg+fHiNrysUCigUimrb5XJ5vf/QaMixpsaScgUsK19jyvXz/Vdx+no+7BVWWP5cT9goq//ONoQx5docDM3Xkq4NEZmGvOJyzN1ZMYZ2ypMd0MHNXuSIqC5EvxUqKioKkZGR6NWrF0JDQ7Fs2TIUFxdjwoQJAIBx48bBy8sLMTExAIB58+bh0UcfRYcOHZCfn49Fixbh+vXrmDhxophpEFE9nU7NxbJ9VwBUTCHYplX9blEkIiLz8eGuP3CnuByd3O3xav/2YodDdSR6YTF27Fjk5ORg1qxZyMzMRPfu3bFnzx79gO4bN25AKv3rloi8vDxMmjQJmZmZaNmyJUJCQnD06FEEBgaKlQIR1VNBiRpvfHceOgEY1cMLo3pWn4CBiIgsy5Grt7HlzC1IJEDMqK6wthJ9dQSqI9ELCwCYMmVKrbc+HTp0qMrzpUuXYunSpc0QFRE1JUEQMH3bRaTll6JtK1vM4+raREQWr7Rcixk/VMzcMe5RX4T4thQ5IjIES0AiEsX/TtzA7vhMyGUSfPp8D9grjOJ7DiIiEtGyfVdwI7cErZ2UmDY0QOxwyEAsLIio2cWnFWD+j5cBAO8ODUBX7xbiBkRGa+XKlWjbti2USiV69+6NkydP1rrv+vXrIZFIqjyUSs55T2Qq4tMK8OWRFADAB+FB/MLJBLGwIKJmVVimxuSNZ1Gu1WFQZ3e89Lif2CGRkdq0aROioqIwe/ZsnD17Ft26dUNYWBiys7NrPcbR0REZGRn6x/Xr15sxYiKqL41Wh3e3XoRWJ2Bk19b4W2f3hx9ERoeFBRE1G0EQEL01DtfvlMCrhQ0+iegKiYTzklPNlixZgkmTJmHChAkIDAzE6tWrYWtri7Vr19Z6jEQigYeHh/5ROREIERm3tb+n4FJ6IZxs5Jj9VBexw6F6YmFBRM1m/dFU/ByXAblMghX/6IEWttZih0RGqry8HGfOnMGgQYP026RSKQYNGoRjx47Vetzdu3fh6+sLHx8fPPPMM7h06VJzhEtEDXDjTgmWxFZMO/7e8M5wdWjctYyo+fDmNSJqFqdTc/Hhz38AAKKHdUaPNpzpg2p3+/ZtaLXaaj0O7u7uSEhIqPEYf39/rF27Fl27dkVBQQE++eQT9O3bF5cuXYK3d81TGatUKqhUKv3zylXI1Wo11Gq1QTFX7m/ocaaIuZqv5s63YobACyhT6/CoX0uEd3NvtnNb0s+2IbkacgwLCyJqcjlFKkzeeBaaP++dnfBYW7FDIjPUp08f9OnTR/+8b9++6Ny5M9asWYP58+fXeExMTAzmzp1bbfvevXtha1u/xRpjY2PrdZwpYq7mq7nyPZktwdFkGeQSAYOccrB79+5mOe+9LOlnW59cS0pK6rwvCwsialIarQ6v/99ZZBWq0MHNHgtHc1wFPZyLiwtkMhmysrKqbM/KyoKHh0ed3kMul6NHjx5ISkqqdZ/o6GhERUXpnxcWFsLHxwdDhgyBo6OjQTGr1WrExsZi8ODBkMvlBh1rapir+WrOfO/cVWH2p0cBqPHGoE6I7Ne8k3lY0s+2IblW9uTWBQsLImpSMbsTcPxaLuysZVj9QgjsOH0g1YG1tTVCQkKwf/9+hIeHAwB0Oh32799f64Kq99NqtYiLi8Pw4cNr3UehUEChqH4/t1wur/cfGg051tQwV/PVHPku2BOP/FI1Ord2xCsDOkAuE2foryX9bOuTqyH7s4Unoiaz7ewtfPXnnOSfRHRDBzd7kSMiUxIVFYXIyEj06tULoaGhWLZsGYqLizFhwgQAwLhx4+Dl5YWYmBgAwLx58/Doo4+iQ4cOyM/Px6JFi3D9+nVMnDhRzDSIqAYHE7Kx80I6pBJg4ehg0YoKalwsLIioSVy8lY/p2+IAAK8/2QHDgluLHBGZmrFjxyInJwezZs1CZmYmunfvjj179ugHdN+4cQNS6V9/jOTl5WHSpEnIzMxEy5YtERISgqNHjyIwMFCsFIioBsUqDWZujwcATHjMj4ukmhEWFkTU6HKKVHhlwxmUa3T4W4Ab3hzUSeyQyERNmTKl1lufDh06VOX50qVLsXTp0maIioga4pO9iUjLL4V3Sxu8NYTtgzlhvxMRNaoytRYvbziNjIIytHO1w9LnukMq5WBtIiICzt3Iw/qjqQCAD58Nhq01v+M2JywsiKjRCIKAd7ZcxLkb+XCykeOryEfgqLSMAXFERPRgaq0O0dviIAjAsz280L+Tq9ghUSNjYUFEjWbFgSTsvJAOK6kEn/+zJ/xc7MQOiYiIjMQXh68hIbMIznbWeH8kxz6ZIxYWRNQodpxPw+LYKwCAec8EoW8HF5EjIiIiY3Et5y6W778KAHh/ZGc421mLHBE1BRYWRNRgx6/dwbTNFwEALz3uh3/0biNyREREZCx0OgHR2+JQrtGhXydXhHf3EjskaiIsLIioQZKyi/DyN6dRrtVhWJAH3hveWeyQiIjIiGw6fRMnUnJhI5fhw/AgSCSc0MNcsbAgonrLKixD5NpTKCzToGebFlg6ljNAERHRX7ILy7Bg1x8AgLeGdIKPs63IEVFTYmFBRPVSUKLGuK9OIi2/FG1b2eLLyEeglMvEDouIiIzInB8voahMg67eTpjwmJ/Y4VATY2FBRAYrLdfixa9PITGrCG4OCmx4qTcH4hERURV7L2ViV1wmZFIJPhrVFTL2aJs9FhZEZJByjQ7//vYMzlzPg6PSCt+8FMqubSIiqqKwTI33d8QDAF7u1w6Bno4iR0TNgYUFEdWZRqvD1E3ncDAxB0q5FGvHP4IADzYWRERU1cd7EpBVqIJvK1u88beOYodDzYSFBRHViVYn4O3NF7ArLhPWMilWvxCCXm2dxQ6LiIiMzOnUXPzv+A0AQMyoYI6/syAsLIjooXQ6ATO2xWH7+YpVtVf+sycG+LuJHRYRERkZlUaLd7dWrGv0917e6Nuei6VaEiuxAyAi46bVCYjedhHfn74FqQRY/lwPDA50FzssIiIyQqsOJiM5pxgu9grM4LpGFoeFBRHVSqsTMG3zBWw7lwapBFg6tjtGdG0tdlhERGSErmQVYdWhJADAnKcD0cKWswVaGhYWRFQjtVaHqO8v4McL6ZBJJfj0uR4sKoiIqEY6nYDobXFQawX8LcANI4LZXlgiFhZEVE1puRaTN57FgYRsyGUSfPZ8TwwN8hA7LCIiMlLfnriOM9fzYGctw/zwIEgkXLPCErGwIKIqCkrVeGn9KZy+ngelXIpV/+yJJwM4poKIiGqWUVCKhXsSAQDvDA2AZwsbkSMisbCwICK9jIJSTFh3CgmZRXBUWmHt+Ec4pSwREdVKEATM2nEJd1Ua9GjTAi886it2SCQiFhZEBACITyvAS1+fQlahCq4OCnzzYig6t+bid0REVLvd8ZmIvZwFuUyCj0Z1hUzKW6AsGQsLIsKBhCxM2XgOJeVadHSzx9rxj8DH2VbssIiIyIgVlKgxe+clAMBr/dvD38NB5IhIbEaxQN7KlSvRtm1bKJVK9O7dGydPnnzg/ps3b0ZAQACUSiWCg4Oxa9euZoqUyLwIgoA1vyZj4tenUVKuxWMdWmHLa31ZVBAR0UPF7P4DOUUqtHe1w+QnO4gdDhkB0QuLTZs2ISoqCrNnz8bZs2fRrVs3hIWFITs7u8b9jx49iueffx4vvfQSzp07h/DwcISHhyM+Pr6ZIycybaXlWvznu/OI2Z0AnQCM7eWDdeND4WQjFzs0IiIycsev3cF3p24CAD4a3RUKK5nIEZExEL2wWLJkCSZNmoQJEyYgMDAQq1evhq2tLdauXVvj/suXL8fQoUMxbdo0dO7cGfPnz0fPnj2xYsWKZo6cyHTllAJ//+9J/HghHVZSCeY90wUfjQ6GtZXoHwlERGTkytRaRG+LAwD8s3cbPMJJPuhPov4VUV5ejjNnzmDQoEH6bVKpFIMGDcKxY8dqPObYsWNV9geAsLCwWvdvTNdyipFdCtzMK0F6fimyi8qQX1KOuyoNVBotdDqhyWMgaqifLmZgUZwMCZlFcLG3xrcTe2Ncn7acc5yIiOrkswNXkXK7GO6OCrw7LEDscMiIiDp4+/bt29BqtXB3rzpHvru7OxISEmo8JjMzs8b9MzMza9xfpVJBpVLpnxcWFgIA1Go11Gq1QfFGfHEChWVW+PD8kVr3sZJKYG0lhbVM+ud/JbC2kkFhJYVCLoXCSgqllQxKuRQ2chkUchlsrWWw+fO/lQ87hRXsFDLYW1vBXmEFe2XFf+2sZZA2w4wLldfG0Gtkqiwh32KVBjF7ErHpdBoACULaOGHZ2G7wcFSabd6W8HO9V33ztZTrQ0QN90dGIdb8eg0AMO+ZIDgqefss/cXsZ4WKiYnB3Llzq23fu3cvbG0NG6BqJciglAE6AdAKgFao/ge+RidAU65FCbT1jvlBJBBgIwNsrCoetlYC7KwAWyvAzgqwkwuwtwLs5YC9XICDHLC3AmT17JuKjY1t3ASMnLnme60Q+DZJhtsqCSQQMMRLQJjnHZw9ckDs0JqFuf5ca2NoviUlJU0UCRGZE61OwPStF6HRCRjaxQNhXTzEDomMjKiFhYuLC2QyGbKysqpsz8rKgodHzf9YPTw8DNo/OjoaUVFR+ueFhYXw8fHBkCFD4Oho2Bz9gwerERsbi8GDB0Mul0MQBGh1AtRaAWqtDmpdxX/LNX8+tDqo7v1/tQ5lai3KNH/+98/nJeValP7534qHBiXlWtwt0+BuuRbFKg2KyjTQ6AQIkKBEC5RoAagAoG69Fy1t5XCxt4argwJu9gq4OSrg7qiEu4MCHk5KtHZSwsXOWt8bolZXzdXcmWu+ZWotlh9IxleXUyEIQGsnJT58OgBFSafNLteamOvPtTb1zbeyJ5eI6EHWH03FhVsFcFBaYe4zXcQOh4yQqIWFtbU1QkJCsH//foSHhwMAdDod9u/fjylTptR4TJ8+fbB//35MnTpVvy02NhZ9+vSpcX+FQgGFQlFtu1wur/cfGvcf2xwL1wuCgDK1DkVlahSWaVBQqkZhqRoFpWrklZQjr0SNgpJy3CkuR+6fj8r/1+oE5JWokVeixtXs4trzkkng4aSEVwsbeDopUZIjQVl8NvxcHdHG2RZuDopmuQ1LTA35d2Fsfr2Sg/e3x+NGbsW30aN7emP204GwkQG7kswr14expFwBw/O1pGtDRPVzM7cEi/cmAgCih3WGu6NS5IjIGIl+K1RUVBQiIyPRq1cvhIaGYtmyZSguLsaECRMAAOPGjYOXlxdiYmIAAG+88Qb69++PxYsXY8SIEfjuu+9w+vRpfPHFF2Km0eQkEglsrGWwsZbBzYCOFp1OQH6pGjlFKmQXlSGnSIWsQhWyCsuQVViGzMIyZOSXIbuoDGqtgJu5pbiZW/rn0TLsuXVJ/14KKyl8W9nCt5Ud2rayhZ+LPfxc7NDe1Q6uDgoO/jUS6fmliNmdgB8vpAMAPByVmB8ehMGBFWOTeD89EREZQhAEzNwej5JyLUL9nPHcIz5ih0RGSvTCYuzYscjJycGsWbOQmZmJ7t27Y8+ePfoB2jdu3IBU+tcAgb59+2Ljxo2YOXMmZsyYgY4dO2L79u0ICgoSKwWjJpVK4GxnDWc76weuiKnR6pBVpEJaXinS80tx/fZdHI+7AomDC27llSEtvxQqjQ5Xsu7iStbdasc7KKzQzs0e7V3t0NHNAR3d7NHR3R4+LW3NvpfDWBSrNFjzazK++O0aytQ6SCVAZN+2eGuIP+wVov+qExGRidp5IR2/XsmBtZUUMaOC2a5TrYzir40pU6bUeuvToUOHqm2LiIhAREREE0dlWaxkUni1sIFXi4obu9RqNdqWJGD48F6Qy+XQaHVIzy9D6p1ipN4pRsrtvx43c0tQpNLgws18XLiZX+V9lXIpOrjZo5O7AwI8HODv4YjOHg7s4WhEZWotNp26iZUHk5BdVDED2iNtW2LWyC4I9nYSOToiIjJlucXlmPvjZQDAf57sgPau9iJHRMbMKAoLMn5WMinatLJFm1a26AfXKq+pNFrcuFOCpOy7SM65i6vZFb0ayTl3UabWIT6tEPFpVQeHOttZI8DDAQEejujc2gGBno7o4GbPlTsNUKbWYvOZW1h1MAkZBWUAAB9nG0QP64xhQR4s3IiIqME++OkycovL4e/ugJf7tRc7HDJyLCyowRRWMnR0d0BH96q3Wml1Aq7fKcaVrCIkZt7FlawiJGQWIuV2MXKLy3E0+Q6OJt/R728llaCDmz0CPR0R2NoRXTydEOjpCCcbDiy91527Kmw4fh3fHLuO3OJyABXjKKY82QF/7+XD1bOJiKhRHL6Sg23n0iCRAB+NDmb7Qg/FwoKajEwqQTtXe7RztcfQe4bAlKm1uJp1F39kFOKPzEJcTi/EHxmFKCzTICGzCAmZRdiGNP3+Ps42+kKji6cjAj0d4eGotKhv5AVBwImUXPzfyRvYHZeJcq0OAODVwgYv92uHsY/4QClnbw8RETWOknIN3tseBwCI7NMWPdq0FDkiMgUsLKjZKeUyBHs7Vbn/XxAEpOWX4o+MIlxKL8Dl9EJcSi9EWn6pfqaqXy79tX5JS1u5vmcj0NMRnVs7op2Lvdl9m3I1qwg/XkjHzgvpSL3z1yJmXb2dMOmJdhgW5AGr+q5+SEREVItPDyTjZm4pPJ2UeDvMX+xwyESwsCCjIJFI4N3SFt4tbfXTogJAfkk5LmcU6guNy+mFSMq5i7wSNX5PuoPfk/66lUouk6CDW+Ug8YpHJ3cHeDqZTu+GRqvD2Rv5OJCQjQMJWVVm4LKzluHp7l74R2gbDsomi7Fy5UosWrQImZmZ6NatGz777DOEhobWuv/mzZvx/vvvIzU1FR07dsTChQsxfPjwZoyYyPTdvAusi78OAPjg2SDOLEh1xn8pZNRa2Fqjb3sX9G3vot9WptbiSlYR/viz4LicUYiEjCIUqTQVt1dlVB0obmctQwf3iilw27naob2rPdq52MHH2Vb024eKVRpczijE6dQ8nEy5g9OpeShSafSvy2US9O/kiqe6eWJQZ3fY8cOdLMimTZsQFRWF1atXo3fv3li2bBnCwsKQmJgINze3avsfPXoUzz//PGJiYjBy5Ehs3LgR4eHhOHv2LKckJ6qjq9l38d8EGXQC8FQ3TzwZ4P7wg4j+xL9SyOQo5TJ09W6Brt4t9NsEQcCtvFL8kVH45yDxIiRmFiHldjGKy7U1ToUrkQCtHZXwcbaFZwslSnOkKD5zC54t7eDuqISbgwItbK0ha+B83VqdgJwiFTIKSnEjtwTJOcW4llMxxuTa7WIIQtX9W9rK0b+TKwYGuGFAJzc42XLwOlmmJUuWYNKkSfoFU1evXo2ff/4Za9euxfTp06vtv3z5cgwdOhTTpk0DAMyfPx+xsbFYsWIFVq9e3ayxE5mii7fyEbn2FArUEnR0s8Pcp7uIHRKZGBYWZBYkEgl8nG3h42yLIV089NvLNbo/Z6aqmP628pF6uwR3VRqkF5Qh/c+pWgEp9ty6fN/7As621nCylcNBYQUHpRy21jJYW0mhsJLB6s+iQ4AAjVZAmUaLMrUOd8s0yC8tR36JGneKy6HV3Vc93MPDUYluPk7o7dcKoX7O6NzascHFDJGpKy8vx5kzZxAdHa3fJpVKMWjQIBw7dqzGY44dO4aoqKgq28LCwrB9+/Zaz6NSqaBSqfTPCwsrejzVarVBq9QfSbqDny6mIy1NisPb4qos7GqOdDodczUzggDsvpSJYpUWbewEfD2uBxysJQb9HpiaytzMOcdKDcnVkGNYWJBZs7aS1jgVriAIyC0uR+qdYtzKK8WN23dx7OIVyFu4IbuoHFmFZcgtLocgAHeKy3Hnz2ld60smlcDdQQHvlrZo52qHdq526OjugCBPJ7g6KBr03kTm6Pbt29BqtXB3r3obhru7OxISEmo8JjMzs8b9MzMzaz1PTEwM5s6dW2373r17YWtrW+d4D2VI8EOqDIAUyM6o83Gmjbmaow6OAiYFaHHq90Nih9JsYmNjxQ6h2dQn15KSkofv9CcWFmSRJBIJWtkr0MpegRDfimq8TXEChg/vCbm84tYjtVaHvJJy3LlbjoJSNYrKNCgqU6NMrYNKo4VKo6vSEyGXSaCUy6CwksJeIUcLWzmcbORwdVDAxV7BXggiIxQdHV2ll6OwsBA+Pj4YMmQIHB0d6/w+3rcK4Hs1B0lJV9GhQ0fIzPibbQDQ6nTM1Qw521ljWKALfjt0AIMHD9a3h+ZKrVYjNjaWuT5EZU9uXbCwIKqFXCaFm4MSbg5KsUMhsjguLi6QyWTIysqqsj0rKwseHh41HuPh4WHQ/gCgUCigUFTvNZTL5QY1viF+Lujq7YRdpVcwfGAHi/gjhbmap8rbXgz9HTBlzPXhx9SVeZfeRERkkqytrRESEoL9+/frt+l0Ouzfvx99+vSp8Zg+ffpU2R+o6PavbX8iImpc7LEgIiKjFBUVhcjISPTq1QuhoaFYtmwZiouL9bNEjRs3Dl5eXoiJiQEAvPHGG+jfvz8WL16MESNG4LvvvsPp06fxxRdfiJkGEZHFYGFBRERGaezYscjJycGsWbOQmZmJ7t27Y8+ePfoB2jdu3KgyS0/fvn2xceNGzJw5EzNmzEDHjh2xfft2rmFBRNRMWFgQEZHRmjJlCqZMmVLja4cOHaq2LSIiAhEREU0cFRER1YRjLIiIiIiIqMFYWBARERERUYNZ3K1QglCx7oAhc/JWUqvVKCkpQWFhodlPS2ZJuQKWlS9zNV/1zbfy87CwsBAODg6QSCx3zRW2EXXDXM2XJeXLXOum8vOw8vPxQSyusCgqKgIA+Pj4iBwJEZFx8fHxQUFBgUELw5kbthFERDUrKiqCk5PTA/eRCHUpP8yITqdDenp6vb6Vq1yR9ebNm2bf8FpSroBl5ctczVd98xUEAUVFRXBwcICjo6NF91iwjagb5mq+LClf5lo3lW2Ep6dnlZn4amJxPRZSqRTe3t4Neg9HR0ez/wdYyZJyBSwrX+ZqvuqT78O+hbIUbCMMw1zNlyXly1wfrq5tBAdvExERERFRg7GwICIiIiKiBmNhYQCFQoHZs2dDoVCIHUqTs6RcAcvKl7maL0vL19hY0vVnrubLkvJlro3P4gZvExERERFR42OPBRERERERNRgLCyIiIiIiajAWFkRERERE1GAsLOrp6aefRps2baBUKtG6dWv861//Qnp6uthhNYnU1FS89NJL8PPzg42NDdq3b4/Zs2ejvLxc7NCaxIcffoi+ffvC1tYWLVq0EDucRrdy5Uq0bdsWSqUSvXv3xsmTJ8UOqdEdPnwYTz31FDw9PSGRSLB9+3axQ2oyMTExeOSRR+Dg4AA3NzeEh4cjMTFR7LAsnqW0EWwfzIsltA8A24imbCNYWNTTwIED8f333yMxMRFbt25FcnIyxowZI3ZYTSIhIQE6nQ5r1qzBpUuXsHTpUqxevRozZswQO7QmUV5ejoiICLz22mtih9LoNm3ahKioKMyePRtnz55Ft27dEBYWhuzsbLFDa1TFxcXo1q0bVq5cKXYoTe7XX3/F5MmTcfz4ccTGxkKtVmPIkCEoLi4WOzSLZiltBNsH82Ep7QPANqJJ2wiBGsWOHTsEiUQilJeXix1Ks/j4448FPz8/scNoUuvWrROcnJzEDqNRhYaGCpMnT9Y/12q1gqenpxATEyNiVE0LgPDDDz+IHUazyc7OFgAIv/76q9ih0D0sqY1g+2CaLLF9EAS2EY2NPRaNIDc3F99++y369u0LuVwudjjNoqCgAM7OzmKHQQYoLy/HmTNnMGjQIP02qVSKQYMG4dixYyJGRo2poKAAAPj7aUQsrY1g+2B62D5YjqZuI1hYNMC7774LOzs7tGrVCjdu3MCOHTvEDqlZJCUl4bPPPsMrr7widihkgNu3b0Or1cLd3b3Kdnd3d2RmZooUFTUmnU6HqVOn4rHHHkNQUJDY4Vg8S2wj2D6YJrYPlqE52ggWFveYPn06JBLJAx8JCQn6/adNm4Zz585h7969kMlkGDduHAQTWm/Q0HwBIC0tDUOHDkVERAQmTZokUuSGq0+uRKZm8uTJiI+Px3fffSd2KGbJktoItg9sH8j8NEcbYdVk72yC3nrrLYwfP/6B+7Rr107//y4uLnBxcUGnTp3QuXNn+Pj44Pjx4+jTp08TR9o4DM03PT0dAwcORN++ffHFF180cXSNy9BczZGLiwtkMhmysrKqbM/KyoKHh4dIUVFjmTJlCn766SccPnwY3t7eYodjliypjWD7UBXbBzJ1zdVGsLC4h6urK1xdXet1rE6nAwCoVKrGDKlJGZJvWloaBg4ciJCQEKxbtw5SqWl1djXkZ2surK2tERISgv379yM8PBxAxb/b/fv3Y8qUKeIGR/UmCAJef/11/PDDDzh06BD8/PzEDslsWVIbwfbBsrB9MF/N3UawsKiHEydO4NSpU3j88cfRsmVLJCcn4/3330f79u1N4psoQ6WlpWHAgAHw9fXFJ598gpycHP1r5vhNxo0bN5Cbm4sbN25Aq9Xi/PnzAIAOHTrA3t5e3OAaKCoqCpGRkejVqxdCQ0OxbNkyFBcXY8KECWKH1qju3r2LpKQk/fOUlBScP38ezs7OaNOmjYiRNb7Jkydj48aN2LFjBxwcHPT3Qzs5OcHGxkbk6CyTJbURbB/OA2D7YGrYRjRhG9Ekc02ZuYsXLwoDBw4UnJ2dBYVCIbRt21Z49dVXhVu3bokdWpNYt26dAKDGhzmKjIysMdeDBw+KHVqj+Oyzz4Q2bdoI1tbWQmhoqHD8+HGxQ2p0Bw8erPFnGBkZKXZoja62381169aJHZrFsqQ2gu0D2wdTxDai6doIyZ8nJSIiIiIiqjfTuhGSiIiIiIiMEgsLIiIiIiJqMBYWRERERETUYCwsiIiIiIiowVhYEBERERFRg7GwICIiIiKiBmNhQUREREREDcbCgoiIiIiIGoyFBRERERERNRgLCyIiIiIiajAWFkRERERE1GAsLIiaWU5ODjw8PLBgwQL9tqNHj8La2hr79+8XMTIiIhIT2wcydRJBEASxgyCyNLt27UJ4eDiOHj0Kf39/dO/eHc888wyWLFkidmhERCQitg9kylhYEIlk8uTJ2LdvH3r16oW4uDicOnUKCoVC7LCIiEhkbB/IVLGwIBJJaWkpgoKCcPPmTZw5cwbBwcFih0REREaA7QOZKo6xIBJJcnIy0tPTodPpkJqaKnY4RERkJNg+kKlijwWRCMrLyxEaGoru3bvD398fy5YtQ1xcHNzc3MQOjYiIRMT2gUwZCwsiEUybNg1btmzBhQsXYG9vj/79+8PJyQk//fST2KEREZGI2D6QKeOtUETN7NChQ1i2bBk2bNgAR0dHSKVSbNiwAb/99hs+//xzscMjIiKRsH0gU8ceCyIiIiIiajD2WBARERERUYOxsCAiIiIiogZjYUFERERERA3GwoKIiIiIiBqMhQURERERETUYCwsiIiIiImowFhZERERERNRgLCyIiIiIiKjBWFgQEREREVGDsbAgIiIiIqIGY2FBREREREQNxsKCiIiIiIga7P8BARucCq2liioAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feed Forward Neural Network Module"
      ],
      "metadata": {
        "id": "pxNPeLXTpN5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"], 4 * cfg['emb_dim']),\n",
        "        GELU(),\n",
        "        nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim']),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "Hek0zsKDpDJi"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)\n",
        "x = torch.randn(2, 3, 768)\n",
        "out = ffn(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90x1V5JtqEdB",
        "outputId": "23b2c0da-13fb-41b5-c978-d83814cbb1cd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Neural Network to illustrate shortcut connections\n"
      ],
      "metadata": {
        "id": "jH7o703JsCby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "  def __init__(self, layer_sizes, use_shortcut):\n",
        "    super().__init__()\n",
        "    self.use_shortcut = use_shortcut\n",
        "    self.layers = nn.ModuleList([\n",
        "        nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
        "                      GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),\n",
        "                      GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),\n",
        "                      GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),\n",
        "                      GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),\n",
        "                      GELU()),\n",
        "    ])\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      layer_output = layer(x)\n",
        "      if self.use_shortcut and x.shape == layer_output.shape:\n",
        "        x = x + layer_output\n",
        "      else:\n",
        "        x = layer_output\n",
        "    return x\n",
        "\n",
        "  def print_gradients(model, x):\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "      if 'weight' in name:\n",
        "        print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "JTtkwnI4qa-U"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "torch.manual_seed(123)\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "                         layer_sizes, use_shortcut=False)"
      ],
      "metadata": {
        "id": "7WJykHjGsVkd"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gradients(model_without_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZyus2cDwctH",
        "outputId": "1083f8fb-4139-4179-b07c-b12b1d359f7a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
            "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
            "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
            "layers.3.0.weight has gradient mean of 0.0013988733990117908\n",
            "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
        "    layer_sizes, use_shortcut=True\n",
        ")\n",
        "print_gradients(model_with_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4icNC5CvkzP",
        "outputId": "d5b16506-47d8-404e-e221-bcc8d57225bf"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.22169828414916992\n",
            "layers.1.0.weight has gradient mean of 0.2069413959980011\n",
            "layers.2.0.weight has gradient mean of 0.3289704918861389\n",
            "layers.3.0.weight has gradient mean of 0.26657360792160034\n",
            "layers.4.0.weight has gradient mean of 1.3258558511734009\n"
          ]
        }
      ]
    }
  ]
}